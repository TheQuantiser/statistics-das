{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File: exercise_0.ipynb\n",
    " - Created: 4 June 2013 Harrison B. Prosper, INFN SOS 2013, Vietri sul Mare, Italy\n",
    " - Adapted for CMSDAS 2016, LPC Fermilab, Harrison B. Prosper\n",
    " - Adapted for CMSDAS 2019, LPC Fermilab, Javier Duarte\n",
    " - Adapted for CMSDAS 2024, LPC Fermilab, Harrison B. Prosper\n",
    " - Adapted for CMSDAS 2026, LPC Fermilab, Mohammad W., Vasilije P.\n",
    " \n",
    "## Description\n",
    "\n",
    "This notebook is a compact, end-to-end tutorial on using **PyROOT** and **RooFit/RooStats** to build a simple model, generate toy data, fit it, and evaluate fit quality. The emphasis is on learning the *RooFit object model* (variables, PDFs, datasets, fit results) and the *workflow patterns* that show up repeatedly in CMS statistics (workspace-driven definitions, likelihood fits, binned/unbinned views of the same data).\n",
    "\n",
    "We use a one-dimensional observable $x$ and a double-exponential PDF with parameters $\\theta \\equiv (a,b,c)$. The notebook then follows the standard pipeline:\n",
    "\n",
    "- **Workspace & factory syntax:** create and store the observable, parameters, PDFs, and datasets in a `RooWorkspace` so the full model lives in one consistent container.\n",
    "- **Toy generation:** generate an unbinned `RooDataSet` of size $T$ directly from the PDF. This provides a controlled environment to validate the fitting and GOF machinery.\n",
    "- **Unbinned fit (Part 1):** fit the PDF to the unbinned dataset with maximum likelihood, save the `RooFitResult`, and inspect parameter values, uncertainties, and correlations.\n",
    "- **Binned fit (Part 2):** bin the same events into a `RooDataHist` with $M$ bins and repeat the fit using a multinomial likelihood (fixed total count). This mirrors the logic of histogram-based fits and templates.\n",
    "- **Goodness-of-fit (Part 3):** compute two binned GOF measures and convert them to **p-values** using asymptotic $\\chi^2$ tail probabilities, giving a quantitative answer to: “are the bin-to-bin deviations typical if the fitted model is true?”\n",
    "\n",
    "\n",
    "ROOT (RooFit/RooStats) documentation: https://root.cern.ch/\n",
    "\n",
    "\n",
    "### Some useful shortcuts\n",
    "\n",
    " - Use **esc r** to disable a cell\n",
    " - Use **esc y** to reactivate it\n",
    " - Use **esc m** to go to markdown mode. Markdown is the typesetting language used in jupyter notebooks. In a markdown cell, double tap the mouse or glide pad (on your laptop) to go to edit mode.\n",
    " - Shift + return to execute a cell (including markdown cells).\n",
    " - If equations don't typeset, try double tapping the cell again, and re-execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Python utilities ---\n",
    "import sys                 # Python runtime utilities (paths, env, argv, etc.)\n",
    "from time import sleep     # simple pauses for pacing/demo (optional)\n",
    "import math                # basic math functions (log, sqrt, etc.) used later\n",
    "\n",
    "# --- ROOT / RooFit via PyROOT ---\n",
    "import ROOT                # gives access to ROOT + RooFit/RooStats classes from Python\n",
    "\n",
    "# --- Local helper utilities for this tutorial ---\n",
    "# Add the CMSDAS helper module directory so we can import plotting style helpers.\n",
    "sys.path.append('../python')\n",
    "from histutil import setStyle, mkhist1   # consistent ROOT plotting style + quick 1D histogram helper\n",
    "\n",
    "# RooFit can be very chatty (INFO/WARNING messages during fitting).\n",
    "# For this short exercise we suppress everything below FATAL to keep output readable.\n",
    "# If anything looks wrong (unexpected fit behavior, NaNs, crashes), comment out the kill line\n",
    "# to re-enable RooFit diagnostics and see what it’s complaining about.\n",
    "msgservice = ROOT.RooMsgService.instance()\n",
    "msgservice.setGlobalKillBelow(ROOT.RooFit.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RooWorkspace = central container for RooFit/RooStats objects (x, parameters, PDFs, data).\n",
    "# Using its factory() lets us define the model with concise strings and reuse/save everything consistently.\n",
    "wspace = ROOT.RooWorkspace(\"CMSDAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model ingredients: **observable** and **parameters**\n",
    "\n",
    "In this exercise we fit a *double-exponential* PDF to data.\n",
    "\n",
    "- **Observable**: $x$ (the quantity we measure and histogram/fit)\n",
    "- **Parameters**: $a, b, c$ (numbers the fit will determine)\n",
    "\n",
    "In RooFit, *everything is an object* (variables, PDFs, datasets, fit results).  \n",
    "\n",
    "A convenient way to create variables is the workspace **factory()**, which parses a short string:\n",
    "\n",
    "```python\n",
    "    wspace.factory(f\"{name}[{initial_value}, {xmin}, {xmax}]\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Observable definition (given)\n",
    "# ------------------------------------------------------------\n",
    "# We'll fit the PDF over x ∈ [0, 20]. Keeping the range explicit\n",
    "# helps later when we integrate the PDF over bins (GOF section).\n",
    "xmin, xmax = 0.0, 20.0\n",
    "wspace.factory(f\"x[0, {xmin}, {xmax}]\")\n",
    "\n",
    "# Choose the number of bins used for (i) display and (ii) the binned fit.\n",
    "# (This does not affect the unbinned likelihood fit we'll do later.)\n",
    "M = 15\n",
    "wspace.var(\"x\").setBins(M)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EXERCISE: define the model parameters a, b, c\n",
    "# ------------------------------------------------------------\n",
    "# Create THREE RooRealVar parameters in the workspace using factory():\n",
    "#\n",
    "#   a : initial value = 0.4, range = [0.0, 1.0]\n",
    "#   b : initial value = 3.0, range = [0.01, 20.0]\n",
    "#   c : initial value = 9.0, range = [0.01, 20.0]\n",
    "#\n",
    "# Notes:\n",
    "# - a is a mixture fraction, so it must stay between 0 and 1.\n",
    "# - b and c are exponential scale parameters, so they must be > 0.\n",
    "#\n",
    "# TODO: write three lines like:\n",
    "#   wspace.factory(\"a[ ... ]\")\n",
    "#   wspace.factory(\"b[ ... ]\")\n",
    "#   wspace.factory(\"c[ ... ]\")\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "parameters = [\"a\", \"b\", \"c\"]\n",
    "P = len(parameters)   # number of floating parameters in the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define double-exponential PDF model\n",
    "\n",
    "The model to be fitted, called `model`, is defined by the probability density function (pdf)\n",
    "$$p(x|a, b, c) = a \\exp(-x/b)/b + (1-a) \\exp(-x/c)/c$$\n",
    "\n",
    "In RooFit we can build this pdf in a few equivalent ways. The goal is the same in each case:\n",
    "create a pdf named `model` that depends on the observable `x` and parameters `a, b, c`.\n",
    "\n",
    "\n",
    "### A) Directly with the workspace factory (string expression)\n",
    "\n",
    "RooFit provides `RooGenericPdf` for simple analytic forms. The factory syntax is:\n",
    "\n",
    "```python\n",
    "  GenericPdf::<user-defined-name>(\"<function>\", {...})\n",
    "```\n",
    "\n",
    "* We drop the `\"Roo\"` prefix (so `RooGenericPdf` → `GenericPdf`).\n",
    "* The braces `{...}` specify the variable list (internally a `RooArgList`) that appear in the expression.\n",
    "\n",
    "Example (create a pdf named `model`):\n",
    "\n",
    "```python\n",
    "  wspace.factory('GenericPdf::model(\"a*exp(-x/b)/b + (1-a)*exp(-x/c)/c\", {x,a,b,c})')\n",
    "```\n",
    "\n",
    "\n",
    "### B) Define the function in C++ (inline), then call it from `GenericPdf`\n",
    "\n",
    "This is useful when the function gets longer, you want to reuse it, or you want C++ compilation/typing.\n",
    "\n",
    "```python\n",
    "  ROOT.gInterpreter.Declare(\n",
    "      \"\"\"\n",
    "  #include <cmath>\n",
    "  double dbexp(double x, double a, double b, double c)\n",
    "  {\n",
    "    return a*exp(-x/b)/b + (1-a)*exp(-x/c)/c;\n",
    "  }\n",
    "  \"\"\"\n",
    "  )\n",
    "  from ROOT import dbexp\n",
    "\n",
    "  wspace.factory('GenericPdf::model(\"dbexp(x,a,b,c)\", {x,a,b,c})')\n",
    "```\n",
    "\n",
    "\n",
    "### C) Load the C++ function from a `.cc` file (same idea as B, but external file)\n",
    "\n",
    "If you already have a function in a standalone file:\n",
    "\n",
    "```python\n",
    "  gROOT.ProcessLine(open(\"<function>.cc\").read())\n",
    "  from ROOT import <function>\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* `open(...).read()` passes the whole file as a string to ROOT’s JIT compiler.\n",
    "* If additional headers/libs are needed, set include/lib paths *before* compiling:\n",
    "\n",
    "```python\n",
    "  gSystem.AddIncludePath(\"-I<path1> ...\")\n",
    "  gSystem.AddLinkedLibs(\"-L<libdir> -l<library> ...\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# EXERCISE: build the PDF named \"model\" in the workspace\n",
    "# ------------------------------------------------------------\n",
    "# Create the double-exponential pdf using ONE of the methods described above:\n",
    "#\n",
    "#   (A) Direct RooGenericPdf expression via wspace.factory(...)\n",
    "#   (B/C) Use a C++ helper function and call it inside GenericPdf\n",
    "#         (a file \"models.cc\" is provided; compile/load it, then call dbexp(x,a,b,c))\n",
    "#\n",
    "# Requirement: after this block, the workspace must contain a pdf named \"model\".\n",
    "#\n",
    "# TODO: implement your chosen method here.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# After you have created it in the workspace, retrieve it as a Python handle:\n",
    "model = wspace.pdf(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a toy dataset from the model\n",
    "\n",
    "Before we can fit anything, we need *data*. In this exercise we create **toy (pseudo-)data** by *sampling* events directly from our PDF `model`. Concretely, `generate()` uses the PDF $p(x\\mid a,b,c)$ as a probability law and returns a list of random draws $x_1,\\dots,x_T$ distributed according to that law.\n",
    "\n",
    "Why do this?\n",
    "\n",
    "- It gives a controlled, end-to-end test of the full workflow:  \n",
    "  **define model → generate toy data → fit (unbinned/binned) → assess goodness-of-fit**.\n",
    "- Because we know the *truth model* used to generate the sample, we can sanity-check that the fit recovers sensible parameter values (up to statistical fluctuations).\n",
    "- It mirrors how we validate statistical procedures in CMS: toys are a lightweight way to stress-test fits, uncertainties, and GOF behavior before moving on to real data and more realistic models.\n",
    "\n",
    "RooFit objects and commands used here\n",
    "\n",
    "- **`defineSet(\"obs\", \"x\")`**: define a *named set* of observables in the workspace (here $x$).  \n",
    "  Many RooFit methods (including `generate`) take a **set** of observables (a `RooArgSet`), even if there is only one variable.\n",
    "- **`set(\"obs\")`**: retrieve that named set from the workspace as a Python handle.\n",
    "- **`model.generate(obs, T)`**: generate an **unbinned** `RooDataSet` with `T` events, i.e. a collection of $T$ sampled $x$-values distributed as $p(x\\mid a,b,c)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# EXERCISE: define observables and generate toy data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 1) Define the set obs = (x) inside the workspace\n",
    "#    Syntax: wspace.defineSet(\"<setName>\", \"<comma-separated variable names>\")\n",
    "# TODO: wspace.defineSet(\"obs\", \"x\")\n",
    "\n",
    "# 2) Retrieve the set as a Python handle\n",
    "#    Syntax: obs = wspace.set(\"<setName>\")\n",
    "# TODO: obs = wspace.set(\"obs\")\n",
    "\n",
    "# 3) Generate an unbinned toy dataset from the PDF\n",
    "T = 400  # number of events to generate\n",
    "# TODO: data = model.generate(obs, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Unbinned maximum-likelihood fit\n",
    "\n",
    "You now have an **unbinned** dataset `data` generated from your PDF `model`. In this part you will fit the parameters $\\theta=(a,b,c)$ by **maximum likelihood** using the *unbinned* likelihood,\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\prod_{i=1}^{T} p(x_i\\mid \\theta),\n",
    "\\qquad\n",
    "\\text{equivalently minimize } \\; -\\ln\\mathcal{L}(\\theta).\n",
    "$$\n",
    "\n",
    "“Unbinned” means we use the individual event values $x_i$ directly (no histogramming). This is typically the most statistically efficient use of the information in the sample.\n",
    "\n",
    "What RooFit does for you\n",
    "When you call `fitTo`, RooFit:\n",
    "- builds the negative log-likelihood from your PDF and dataset,\n",
    "- runs the minimizer (typically Minuit/Minuit2) to find best-fit values $\\hat{\\theta}$,\n",
    "- estimates parameter uncertainties and correlations from the curvature near the minimum,\n",
    "- and returns a `RooFitResult` so you can inspect or reuse the fit outcome.\n",
    "\n",
    "Key commands / objects\n",
    "\n",
    "- **`ROOT.TStopwatch()`**: simple timing utility (`Start()`, `RealTime()`) so you can compare runtimes (useful later when you contrast unbinned vs binned fits or change $T$).\n",
    "- **`model.fitTo(data, ROOT.RooFit.Save())`**: perform the unbinned ML fit and **return** a `RooFitResult` (using `Save()` so the result is not lost).\n",
    "- **`results.Print()`**: print best-fit parameter values, uncertainties, and fit-status information.\n",
    "- **`results.correlation(p1, p2)`**: correlation coefficient between two fitted parameters (helps diagnose degeneracies, e.g. between the two exponential scales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# PART 1: unbinned fit of model to generated data\n",
    "# ------------------------------------------------------------\n",
    "print(\"=\" * 80)\n",
    "print(\"\\t\\tunbinned fit to toy data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1) Start a stopwatch to time the fit\n",
    "# TODO:\n",
    "# swatch = ROOT.TStopwatch()\n",
    "# swatch.Start()\n",
    "\n",
    "# 2) Perform the unbinned fit and SAVE the fit result\n",
    "#    Syntax: results = model.fitTo(data, ROOT.RooFit.Save())\n",
    "# TODO: results = model.fitTo(data, ROOT.RooFit.Save())\n",
    "\n",
    "# 3) Print timing information\n",
    "# TODO: print(\"real time: {:.3f} s\".format(swatch.RealTime()))\n",
    "\n",
    "# 4) Print the fit result summary (parameter values, errors, etc.)\n",
    "# TODO:\n",
    "# print(\"=\" * 80)\n",
    "# results.Print()\n",
    "\n",
    "# 5) Print the correlation matrix for the fitted parameters\n",
    "#    Hint: results.correlation(\"a\",\"b\") returns the correlation coefficient.\n",
    "# TODO:\n",
    "# print(\"\\tcorrelation matrix\")\n",
    "# header = \"{:>10s}\".format(\"\")\n",
    "# for p in parameters:\n",
    "#     header += \"{:>10s}\".format(p)\n",
    "# print(header)\n",
    "#\n",
    "# for p1 in parameters:\n",
    "#     row = \"{:>10s}\".format(p1)\n",
    "#     for p2 in parameters:\n",
    "#         row += \"{:10.3f}\".format(results.correlation(p1, p2))\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fitted model over the data\n",
    "\n",
    "After the unbinned fit, we want a quick visual check: plot the **dataset** and overlay the **fitted PDF** as a function of the observable $x$.\n",
    "\n",
    "RooFit plotting is done through a **frame** object:\n",
    "- **`xframe = x.frame()`**: create a `RooPlot` frame for the variable $x$ (this is the canvas “staging area” where curves/points get added).\n",
    "- **`data.plotOn(xframe)`**: add the dataset points (with Poisson error bars) to the frame.\n",
    "- **`model.plotOn(xframe)`**: add the PDF curve (using the *current* parameter values, i.e. the post-fit ones).\n",
    "- **`model.paramOn(xframe)`**: add a small parameter box to the frame (best-fit values and errors).\n",
    "- **`xframe.Draw()`**: draw everything currently stored on the frame.\n",
    "- **`TCanvas(...); SaveAs(...)`**: standard ROOT canvas creation and file output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Plot results of the unbinned fit\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 1) Create a RooPlot frame for the observable x\n",
    "#    Syntax: xframe = wspace.var(\"x\").frame()\n",
    "# TODO:\n",
    "# xframe = wspace.var(\"x\").frame()\n",
    "\n",
    "# 2) Optional: adjust the y-axis range for readability\n",
    "#    (These numbers depend on T and your binning/plot settings.)\n",
    "# TODO:\n",
    "# xframe.SetMinimum(0.0)\n",
    "# xframe.SetMaximum(100.0)\n",
    "\n",
    "# 3) Add the dataset points to the frame\n",
    "#    Syntax: data.plotOn(xframe)\n",
    "# TODO:\n",
    "# data.plotOn(xframe)\n",
    "\n",
    "# 4) Overlay the fitted model curve on the same frame\n",
    "#    Syntax: model.plotOn(xframe)\n",
    "# TODO: model.plotOn(xframe)\n",
    "\n",
    "# 5) Add a parameter box to the plot\n",
    "#    Syntax: model.paramOn(xframe)\n",
    "# TODO: model.paramOn(xframe)\n",
    "\n",
    "# 6) Draw on a canvas and save\n",
    "setStyle()\n",
    "c1 = ROOT.TCanvas(\"fig_unbinnedFit\", \"fit\", 600, 500)\n",
    "\n",
    "# TODO:\n",
    "# xframe.Draw()\n",
    "# c1.Draw()\n",
    "# c1.SaveAs(\"fig_unbinnedFit.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Do a binned fit\n",
    "\n",
    "So far you fit `model` to the **unbinned** dataset `data` (a list of event values $x_i$). Now you will bin the *same* events into a `RooDataHist` and fit using **binned** likelihoods.\n",
    "\n",
    "`RooDataHist` is RooFit’s histogram-like dataset. It is defined with respect to a set of observables (here `obs = {x}`), and it uses the binning attached to `x` (set earlier via `x.setBins(M)`). After binning, the data are summarized by counts $N_i$ in each bin $i=1,\\dots,M$, with total\n",
    "$$\n",
    "T \\equiv \\sum_{i=1}^{M} N_i.\n",
    "$$\n",
    "\n",
    "Your PDF $p(x\\mid a,b,c)$ is a *density*. To compare to binned counts, convert it into bin probabilities\n",
    "$$\n",
    "p_i(a,b,c) \\equiv \\int_{\\text{bin }i} p(x\\mid a,b,c)\\,dx,\n",
    "\\qquad \\sum_{i=1}^{M} p_i = 1,\n",
    "$$\n",
    "and (given the observed total $T$) the corresponding expected bin counts\n",
    "$$\n",
    "n_i(a,b,c) \\equiv T\\,p_i(a,b,c).\n",
    "$$\n",
    "\n",
    "There are two standard likelihood models for binned counts. The difference is whether you **model the total rate** (overall normalization) in addition to the **shape** across bins.\n",
    "\n",
    "**A) Multinomial (non-extended; condition on the observed total $T$)**  \n",
    "Here you treat $T$ as fixed *by construction* and fit only the shape parameters $(a,b,c)$ through the bin fractions $p_i$:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{multi}}(a,b,c)\n",
    "=\n",
    "\\frac{T!}{N_1!\\cdots N_M!}\\prod_{i=1}^{M} p_i(a,b,c)^{N_i}.\n",
    "$$\n",
    "Use this when you explicitly want to remove any information from the overall event count and constrain the fit using only how events are distributed in $x$ (i.e. a **shape-only** fit). In this exercise, because the dataset was generated with a fixed size $T$, the multinomial likelihood is the most direct binned analogue of the unbinned shape fit.\n",
    "\n",
    "**B) Extended likelihood (binned product of Poissons; fit rate + shape)**  \n",
    "Here you introduce a yield parameter $\\nu$ (the expected total number of events in the fitted range) and model each bin count as Poisson with mean\n",
    "$$\n",
    "\\mu_i(\\nu,a,b,c) \\equiv \\nu\\,p_i(a,b,c),\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "\\mathcal{L}_{\\text{ext}}(\\nu,a,b,c)\n",
    "=\n",
    "\\prod_{i=1}^{M}\\text{Pois}\\!\\left(N_i \\mid \\mu_i(\\nu,a,b,c)\\right)\n",
    "=\n",
    "\\prod_{i=1}^{M}\\frac{\\mu_i^{N_i}e^{-\\mu_i}}{N_i!}.\n",
    "$$\n",
    "This likelihood uses **both**:  \n",
    "- the *shape* information through the $p_i(a,b,c)$, and  \n",
    "- the *rate* information through how well $\\nu$ predicts the observed total $T$ (since $\\sum_i \\mu_i = \\nu$).\n",
    "\n",
    "Use this when the absolute normalization carries physics information or constraints (e.g. signal strength, expected yields from luminosity$\\times$cross section$\\times$acceptance, or when comparing components whose relative normalizations are parameters). In real analyses, this is the default when you want the fit to learn from *both* the histogram shape and the total event count.\n",
    "\n",
    "### RooFit switch\n",
    "RooFit selects between these with **extended mode**:\n",
    "- `Extended(False)` → multinomial (condition on $T$; shape-only)\n",
    "- `Extended(True)`  → extended likelihood (introduce/floating yield $\\nu$; rate + shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# PART 2: Bin the data (RooDataHist) and do a binned fit\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# EXERCISE (uncomment each TODO line when you're ready):\n",
    "#\n",
    "# 1) Build a binned dataset (RooDataHist) from the observable set \"obs\".\n",
    "#    Syntax:\n",
    "#      ROOT.RooDataHist(<name>, <title>, <RooArgSet_of_observables>)\n",
    "#\n",
    "# 2) Fill it by binning the unbinned dataset \"data\".\n",
    "#    Hint: RooDataHist.add(...) will read events from a RooDataSet and increment bins.\n",
    "#\n",
    "# 3) Print a verbose summary so you can verify:\n",
    "#    - which observable(s) are binned (here: x),\n",
    "#    - the binning (taken from x.setBins(M)),\n",
    "#    - the resulting bin contents.\n",
    "#\n",
    "# 4) Fit the existing PDF \"model\" to the binned data and store the RooFitResult.\n",
    "#    Save() returns a RooFitResult object you can print/inspect.\n",
    "#    Extended(False) conditions on the observed total count (multinomial).\n",
    "#    (Optional later: switch to Extended(True) for an extended / multi-Poisson-style fit.)\n",
    "\n",
    "# 1) Create the binned dataset container\n",
    "# TODO: hdata = ROOT.RooDataHist(\"hdata\", \"binned data\", obs)\n",
    "\n",
    "# 2) Bin the unbinned events into hdata\n",
    "# TODO: hdata.add(data)\n",
    "\n",
    "# 3) Inspect the binned dataset\n",
    "# TODO: print(\"=\" * 40)\n",
    "# TODO: hdata.Print(\"verbose\")\n",
    "# TODO: print(\"=\" * 40)\n",
    "\n",
    "# 4) Perform the binned fit\n",
    "# TODO: results2 = model.fitTo(hdata, ROOT.RooFit.Save(), ROOT.RooFit.Extended(False))\n",
    "\n",
    "# Inspect the fit result\n",
    "# TODO: results2.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Plot the binned-fit result\n",
    "# ------------------------------------------------------------\n",
    "# Visualize the binned dataset (hdata) and overlay the fitted PDF (model)\n",
    "# on a new RooPlot frame, so it doesn't overwrite the unbinned plot.\n",
    "\n",
    "# Create a fresh canvas for the binned-fit plot\n",
    "# TODO: c2 = ROOT.TCanvas(\"fig_binnedFit\", \"binned fit\", 500, 500)\n",
    "\n",
    "# Create a fresh RooPlot frame for x\n",
    "# TODO: xframe2 = wspace.var(\"x\").frame()\n",
    "\n",
    "# Optional: set a visible y-axis range for this plot (adjust as needed)\n",
    "# TODO: xframe2.SetMinimum(0)\n",
    "# TODO: xframe2.SetMaximum(100)\n",
    "\n",
    "# Plot the binned data and overlay the fitted model\n",
    "# TODO: hdata.plotOn(xframe2)\n",
    "# TODO: model.plotOn(xframe2)\n",
    "\n",
    "# Optional: print parameter values/uncertainties on the plot\n",
    "# TODO: model.paramOn(xframe2)\n",
    "\n",
    "# Render + save\n",
    "# TODO: xframe2.Draw()\n",
    "# TODO: c2.Draw()\n",
    "# TODO: c2.SaveAs(\".png\")\n",
    "\n",
    "# Separator for notebook output\n",
    "# TODO: print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: Do a bit of statistics (goodness-of-fit and p-values)\n",
    "\n",
    "So far we have generated $T$ events, then fit the double-exponential model both unbinned and binned (with $M$ bins). The fit returns best-fit parameters $\\hat{\\theta}$ (here $\\theta=(a,b,c)$), but we still need to check whether the fitted model provides an acceptable description of the *binned* data.\n",
    "\n",
    "**Goodness-of-fit (gof) question:**  \n",
    "        ```If the fitted model were true, how surprising are the observed bin-to-bin deviations?```\n",
    "\n",
    "### Notation\n",
    "- $M$: number of $x$ bins  \n",
    "- $T$: total event count  \n",
    "- $N_i$: observed count in bin $i$  \n",
    "- $n_i$: expected (mean) count in bin $i$ under the fitted model,\n",
    "  $$\n",
    "  n_i \\;=\\; T \\int_{\\text{bin }i} p(x \\mid \\hat{\\theta})\\,dx .\n",
    "  $$\n",
    "\n",
    "Because $p(x\\mid\\hat{\\theta})$ is a density, we integrate it over each bin to predict counts. That is why we build a RooFit integral over the current bin range.\n",
    "\n",
    "\n",
    "### Two gof statistics\n",
    "We compute two standard measures, both evaluated at $\\hat{\\theta}$:\n",
    "\n",
    "**1) Pearson chi-square**\n",
    "$$\n",
    "X \\;=\\; \\sum_{i=1}^{M} \\frac{(N_i - n_i)^2}{n_i}.\n",
    "$$\n",
    "\n",
    "**2) Likelihood-ratio (deviance)**\n",
    "$$\n",
    "Y \\;=\\; -2 \\log \\left[\\frac{p(\\boldsymbol{N}\\mid \\boldsymbol{n})}{p(\\boldsymbol{N}\\mid \\boldsymbol{N})}\\right].\n",
    "$$\n",
    "Here $\\boldsymbol{N}=(N_1,\\dots,N_M)$ and $\\boldsymbol{n}=(n_1,\\dots,n_M)$. The denominator is the “saturated” model (perfect bin-by-bin fit), so $Y$ measures how much worse our fitted model is than a perfect description of the histogram.\n",
    "\n",
    "**Practical note:** we restrict to bins with $N_i>5$ to stay in the regime where asymptotic approximations are more reliable.\n",
    "\n",
    "\n",
    "### Degrees of freedom and p-values\n",
    "Let $P$ be the number of fitted parameters (here $P=3$), and let $K$ be the number of retained bins (after applying $N_i>5$).\n",
    "\n",
    "Assuming asymptotia and $H_0$ (“the model is correct”), both $X$ and $Y$ are approximately $\\chi^2$-distributed with\n",
    "$$\n",
    "\\text{ndf} \\;=\\; K - P - 1,\n",
    "$$\n",
    "where the “$-1$” reflects the fixed-total constraint $\\sum_i N_i = T$ (multinomial conditioning).\n",
    "\n",
    "For either statistic $Z\\in\\{X,Y\\}$, the p-value is the upper-tail probability\n",
    "$$\n",
    "p\\text{-value} \\;=\\; \\Pr\\!\\left(Z \\ge Z_{\\text{obs}} \\mid H_0\\right).\n",
    "$$\n",
    "Small p-values suggest the observed deviations are unlikely under the model; large p-values suggest they are consistent with statistical fluctuations.\n",
    "\n",
    "In the code we compute these tails with `ROOT.TMath.Prob(Z, ndf)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# PART 3: Goodness-of-fit on binned data (X, Y, and p-values)\n",
    "# ------------------------------------------------------------\n",
    "# Goal: compare observed bin counts N_i to expected counts n_i\n",
    "# from the fitted PDF. Since a PDF is a *density*, we must\n",
    "# integrate it over each x-bin to predict n_i.\n",
    "#\n",
    "# EXERCISE:\n",
    "# 1) Build a normalized integral of the PDF over a named range \"x-bin\".\n",
    "#    - Create a normalization set: ROOT.RooFit.NormSet(obs)\n",
    "#    - Define a named x-range: wspace.var(\"x\").setRange(\"x-bin\", lo, hi)\n",
    "#    - Create the integral: model.createIntegral(obs, normSet, ROOT.RooFit.Range(\"x-bin\"))\n",
    "#\n",
    "# 2) Loop over bins to compute n_i = T * (integral over bin i), then accumulate:\n",
    "#      X = Σ (N_i - n_i)^2 / n_i\n",
    "#      Y = -2 Σ N_i ln(n_i / N_i)\n",
    "#    Use only bins with N_i > 5 (asymptotic regime).\n",
    "#\n",
    "# 3) Convert X and Y to p-values using χ^2 tail probabilities:\n",
    "#      ndf = K - P - 1   (K = number of bins used, P = #fit parameters)\n",
    "#      p = ROOT.TMath.Prob(Z, ndf)\n",
    "\n",
    "# 1) Normalized integral over a named bin-range\n",
    "# TODO:\n",
    "# normSet = ROOT.RooFit.NormSet(obs)\n",
    "\n",
    "# TODO:\n",
    "# wspace.var(\"x\").setRange(\"x-bin\", xmin, xmax)\n",
    "\n",
    "# TODO:\n",
    "# integral = model.createIntegral(obs, normSet, ROOT.RooFit.Range(\"x-bin\"))\n",
    "\n",
    "# 2) Loop over bins and accumulate X, Y\n",
    "dx = float(xmax - xmin) / M\n",
    "X, Y = 0.0, 0.0\n",
    "total = 0.0  # sanity check: Σ n_i should be ~ T\n",
    "K = 0         # number of bins used (N_i > 5)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"%5s\\t%10s %5s %10s\" % (\"bin\", \"binlow\", \"count\", \"mean\"))\n",
    "\n",
    "for ii in range(M):\n",
    "    # Observed count N_i from the RooDataHist\n",
    "    ibin = hdata.get(ii)   # selects bin ii (needed before weight())\n",
    "    Ni   = hdata.weight()  # bin content (count)\n",
    "\n",
    "    # Bin edges [x, x+dx] and integral over that range\n",
    "    x = xmin + ii * dx\n",
    "    # TODO:\n",
    "    # wspace.var(\"x\").setRange(\"x-bin\", x, x + dx)\n",
    "\n",
    "    # TODO:\n",
    "    # ni = T * integral.getVal()\n",
    "\n",
    "    # TODO:\n",
    "    # print(\"{:5d}\\t{:10.3f} {:5d} {:10.1f}\".format(ii + 1, x, int(Ni), ni))\n",
    "\n",
    "    # TODO:\n",
    "    # total += ni\n",
    "\n",
    "    # Use only bins with N_i > 5\n",
    "    if Ni < 5:\n",
    "        continue\n",
    "\n",
    "    # TODO:\n",
    "    # K += 1\n",
    "    # X += (Ni - ni)**2 / ni\n",
    "    # Y += Ni * math.log(ni / Ni)\n",
    "\n",
    "# Finish Y\n",
    "# TODO:\n",
    "# Y *= -2\n",
    "\n",
    "# 3) Convert to p-values via χ^2 tail probabilities\n",
    "ndf = K - P - 1\n",
    "\n",
    "if ndf > 0:\n",
    "    # TODO:\n",
    "    # pvalueX = ROOT.TMath.Prob(X, ndf)\n",
    "    # pvalueY = ROOT.TMath.Prob(Y, ndf)\n",
    "    pass\n",
    "else:\n",
    "    pvalueX, pvalueY = 1.0, 1.0\n",
    "\n",
    "print(\"=\" * 80)\n",
    "# TODO:\n",
    "# print(\"Int p(x|xi) dx ={:6.1f}\\n\".format(total))\n",
    "# print(\"ChiSq/ndf = {:6.1f}/{:d} (using X)\".format(X, ndf))\n",
    "# print(\"p-value   = {:9.4f}\\n\".format(pvalueX))\n",
    "# print(\"ChiSq/ndf = {:6.1f}/{:d} (using Y)\".format(Y, ndf))\n",
    "# print(\"p-value   = %9.4f\" % pvalueY)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "combine-634",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
